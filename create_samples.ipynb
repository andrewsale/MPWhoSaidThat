{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baa90fd",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-10-15T00:05:30.553011Z",
     "iopub.status.busy": "2022-10-15T00:05:30.552549Z",
     "iopub.status.idle": "2022-10-15T00:05:31.680739Z",
     "shell.execute_reply": "2022-10-15T00:05:31.679510Z"
    },
    "papermill": {
     "duration": 1.140287,
     "end_time": "2022-10-15T00:05:31.683572",
     "exception": false,
     "start_time": "2022-10-15T00:05:30.543285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e52a824",
   "metadata": {
    "papermill": {
     "duration": 0.004632,
     "end_time": "2022-10-15T00:05:31.693441",
     "exception": false,
     "start_time": "2022-10-15T00:05:31.688809",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load and prepare the data\n",
    "\n",
    "First load the data, then we add a word length feature and instpect its statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92783da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T00:05:31.705061Z",
     "iopub.status.busy": "2022-10-15T00:05:31.704678Z",
     "iopub.status.idle": "2022-10-15T00:05:33.693524Z",
     "shell.execute_reply": "2022-10-15T00:05:33.692383Z"
    },
    "papermill": {
     "duration": 1.998083,
     "end_time": "2022-10-15T00:05:33.696499",
     "exception": false,
     "start_time": "2022-10-15T00:05:31.698416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "speeches_df = pd.read_csv('./Processed_speeches/speeches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a018f8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T00:05:33.708902Z",
     "iopub.status.busy": "2022-10-15T00:05:33.708517Z",
     "iopub.status.idle": "2022-10-15T00:05:34.682300Z",
     "shell.execute_reply": "2022-10-15T00:05:34.680984Z"
    },
    "papermill": {
     "duration": 0.983263,
     "end_time": "2022-10-15T00:05:34.684912",
     "exception": false,
     "start_time": "2022-10-15T00:05:33.701649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "speeches_df['Word length'] = speeches_df['Speech'].apply(lambda x : len(x.split(' ')) if isinstance(x,str) else 0)\n",
    "speeches_df['Word length'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51958c2a",
   "metadata": {
    "papermill": {
     "duration": 0.004959,
     "end_time": "2022-10-15T00:05:34.695196",
     "exception": false,
     "start_time": "2022-10-15T00:05:34.690237",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we will select only those speeches by Labour or Conservatives speakers, adn identify them with labels:\n",
    "\n",
    "* 0 for Labour\n",
    "* 1 for Conservative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67506e3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T00:05:34.707668Z",
     "iopub.status.busy": "2022-10-15T00:05:34.707243Z",
     "iopub.status.idle": "2022-10-15T00:05:34.731097Z",
     "shell.execute_reply": "2022-10-15T00:05:34.729843Z"
    },
    "papermill": {
     "duration": 0.03341,
     "end_time": "2022-10-15T00:05:34.733847",
     "exception": false,
     "start_time": "2022-10-15T00:05:34.700437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tory_labour = {'Conservative Party', 'Labour Party', 'Labour Co-operative'}\n",
    "tory_labour_speeches = speeches_df[speeches_df['Party'].isin(tory_labour)].dropna(subset=['Speech'])\n",
    "tory_labour_speeches['Label'] = tory_labour_speeches.loc[:,'Party'].apply(lambda x : 1 if x=='Conservative Party' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd2f701",
   "metadata": {
    "papermill": {
     "duration": 0.004967,
     "end_time": "2022-10-15T00:05:34.744273",
     "exception": false,
     "start_time": "2022-10-15T00:05:34.739306",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## How many speeches should we use in our sample?\n",
    "\n",
    "We saw that the median speech has length around 800 words. If we use subsamples of length 100 words and allow for 50 words of overlap between sample then we can get 16 samples (including one at 50 words length) from the average speech.\n",
    "\n",
    "The total length of Labour speeches is almost 4,000,000 words. Taking 100 word subsamples, and allowing for 50 word overlaps, this gives us almost 80,000 samples. This is roughly half the number we get using Conservative speeches.\n",
    "\n",
    "Thus, taking 150,000 samples in total will give a good variety of speeches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b14560",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T00:05:34.757118Z",
     "iopub.status.busy": "2022-10-15T00:05:34.756022Z",
     "iopub.status.idle": "2022-10-15T00:05:34.767292Z",
     "shell.execute_reply": "2022-10-15T00:05:34.766005Z"
    },
    "papermill": {
     "duration": 0.020117,
     "end_time": "2022-10-15T00:05:34.769700",
     "exception": false,
     "start_time": "2022-10-15T00:05:34.749583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tory_labour_speeches[tory_labour_speeches.Label == 0]['Word length'].sum() /50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a125d332",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T00:05:34.782632Z",
     "iopub.status.busy": "2022-10-15T00:05:34.782233Z",
     "iopub.status.idle": "2022-10-15T00:05:34.792598Z",
     "shell.execute_reply": "2022-10-15T00:05:34.791441Z"
    },
    "papermill": {
     "duration": 0.019753,
     "end_time": "2022-10-15T00:05:34.795079",
     "exception": false,
     "start_time": "2022-10-15T00:05:34.775326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tory_labour_speeches[tory_labour_speeches.Label == 1]['Word length'].sum() /50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0095af",
   "metadata": {
    "papermill": {
     "duration": 0.005014,
     "end_time": "2022-10-15T00:05:34.805500",
     "exception": false,
     "start_time": "2022-10-15T00:05:34.800486",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper functions\n",
    "\n",
    "* `train_val_test_split`\n",
    "\n",
    "We make the split on the speech level (before taking samples from each speech). This ensures that there is no leakage between train and test sets.\n",
    "\n",
    "We upsample the Labout speeches (randomly select more than there are, with replacement) so that in the train and validation sets Labour and Conservatives are equally represented. At the end of the day, the number of sample speeches we take is chosen by looking at the number of (unique) Labour speeches.\n",
    "\n",
    "Note that the Conservative speeches tend to be longer than the Labour speeches, and since the sampling weighs the speeches by their word count, it means we will ultimately end up with more Conservative speech samples anyway, despite doing upsampling.\n",
    "\n",
    "* `random_sample`\n",
    "\n",
    "Takes a whole speech and randomly pulls out a subspeech of the given length (and allowing for shorter speeches to be extracted with a given probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05e189d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T00:05:34.817940Z",
     "iopub.status.busy": "2022-10-15T00:05:34.817504Z",
     "iopub.status.idle": "2022-10-15T00:05:34.828537Z",
     "shell.execute_reply": "2022-10-15T00:05:34.827262Z"
    },
    "papermill": {
     "duration": 0.019918,
     "end_time": "2022-10-15T00:05:34.830761",
     "exception": false,
     "start_time": "2022-10-15T00:05:34.810843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_val_test_split(data, split=[0.8, 0.1, 0.1], random_state=1):\n",
    "    '''\n",
    "    Splits the dataset into three parts by the weights given in the split argument. \n",
    "    Note that the output train and validation sets have the same number of Labour and Conservative speeches by upsampling the Labour speeches.\n",
    "    \n",
    "    Args:\n",
    "        data --- the set to split\n",
    "        split --- the relative sizes of the three output sets\n",
    "        random_state\n",
    "    '''\n",
    "    # Check split weights are correctly input and add up to one\n",
    "    if len(split) > 3:\n",
    "        raise ValueError('Split should contain at most 3 values.')\n",
    "    while len(split)<3:\n",
    "        split.append(0)\n",
    "    split_sum = split[0]+split[1]+split[2]\n",
    "    if split_sum != 1:\n",
    "        for i in range(3):\n",
    "            split[i] /= split_sum\n",
    "    \n",
    "    # Perform the split\n",
    "    train_val, test = train_test_split(data, test_size=split[2], random_state=random_state, stratify=data['Party'])\n",
    "    train_val_0 = train_val[train_val.Label == 0]\n",
    "    train_val_1 = train_val[train_val.Label == 1]\n",
    "    train_val_0_upsample = resample(train_val_0, replace=True, n_samples = train_val_1.shape[0])\n",
    "    train_val = pd.concat([train_val_0_upsample, train_val_1],ignore_index=True)\n",
    "    train, val = train_test_split(train_val, train_size=split[0]/(split[0]+split[1]), random_state=random_state, stratify=train_val['Label'])\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db80ada0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T00:05:34.843723Z",
     "iopub.status.busy": "2022-10-15T00:05:34.842831Z",
     "iopub.status.idle": "2022-10-15T00:05:34.849685Z",
     "shell.execute_reply": "2022-10-15T00:05:34.848647Z"
    },
    "papermill": {
     "duration": 0.01601,
     "end_time": "2022-10-15T00:05:34.852138",
     "exception": false,
     "start_time": "2022-10-15T00:05:34.836128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def random_sample(speech, length=100, shorten_prob=0.1):\n",
    "    '''\n",
    "    Randomly selects a substring from the given speech.\n",
    "    \n",
    "    Args:\n",
    "        speech: str  -- the speech to sample from.\n",
    "        length: int (default 100)  -- the desired maximum length of sample, in number of words.\n",
    "        shorten_prob: float (default 0.1)  -- the probability that we take a sample that is shorter than the desired length.\n",
    "    '''\n",
    "    split_speech = speech.split()\n",
    "    first_index = int(np.random.uniform(0, len(split_speech)-25))\n",
    "    random_shortenizer = np.random.uniform() < shorten_prob\n",
    "    if random_shortenizer:\n",
    "        length = int(np.random.uniform(25,length-10))\n",
    "    last_index = min(len(split_speech), first_index + length)\n",
    "    return \" \".join(split_speech[first_index:last_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b8e09b",
   "metadata": {
    "papermill": {
     "duration": 0.005135,
     "end_time": "2022-10-15T00:05:34.862790",
     "exception": false,
     "start_time": "2022-10-15T00:05:34.857655",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Take samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18119543",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T00:05:34.875104Z",
     "iopub.status.busy": "2022-10-15T00:05:34.874676Z",
     "iopub.status.idle": "2022-10-15T00:05:34.884085Z",
     "shell.execute_reply": "2022-10-15T00:05:34.883086Z"
    },
    "papermill": {
     "duration": 0.018371,
     "end_time": "2022-10-15T00:05:34.886436",
     "exception": false,
     "start_time": "2022-10-15T00:05:34.868065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_all_samples(speeches, full_size = 50000, split=[0.8,0.1,0.1], sample_length=100, shorten_prob=0.1, random_state=1):\n",
    "    # split the set and save the full speeches split into train/dev/test sets\n",
    "    train, val, test = train_val_test_split(speeches, split = split, random_state=random_state)\n",
    "    train.to_csv('./Processed_speeches/full_train.csv')\n",
    "    val.to_csv('./Processed_speeches/full_val.csv')\n",
    "    test.to_csv('./Processed_speeches/full_test.csv')\n",
    "    # define the function that obtains the random subpeech\n",
    "    get_sample = partial(random_sample, length=sample_length, shorten_prob=shorten_prob)\n",
    "    # instantialize a list to collect the output dataframes\n",
    "    output = []\n",
    "    # cycle through the three sets\n",
    "    for i, df in enumerate([train, val, test]):\n",
    "        # sample the rows, with replacement and weighted by word length\n",
    "        sampled_rows = df.sample(int(full_size*split[i]), \n",
    "                                 replace=True, \n",
    "                                 weights='Word length', \n",
    "                                 axis=0, \n",
    "                                 ignore_index=True, \n",
    "                                 random_state=1\n",
    "                                )\n",
    "        # take sample from each speech\n",
    "        sampled_rows['Speech'] = sampled_rows['Speech'].apply(get_sample)\n",
    "        # append to output\n",
    "        output.append(sampled_rows)\n",
    "    return output        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9217726a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T00:05:34.899371Z",
     "iopub.status.busy": "2022-10-15T00:05:34.898357Z",
     "iopub.status.idle": "2022-10-15T00:06:08.859246Z",
     "shell.execute_reply": "2022-10-15T00:06:08.858202Z"
    },
    "papermill": {
     "duration": 33.970202,
     "end_time": "2022-10-15T00:06:08.861965",
     "exception": false,
     "start_time": "2022-10-15T00:05:34.891763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train, val, test = get_all_samples(tory_labour_speeches,\n",
    "                                   full_size = 150000, \n",
    "                                   split = [0.8,0.1,0.1],\n",
    "                                   sample_length = 100,\n",
    "                                   shorten_prob = 0.1\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb576d44",
   "metadata": {
    "papermill": {
     "duration": 0.005034,
     "end_time": "2022-10-15T00:06:08.873663",
     "exception": false,
     "start_time": "2022-10-15T00:06:08.868629",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Summary and save\n",
    "\n",
    "Now let's see the breakdown of our sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9754a9f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T00:06:08.885881Z",
     "iopub.status.busy": "2022-10-15T00:06:08.885496Z",
     "iopub.status.idle": "2022-10-15T00:06:08.895272Z",
     "shell.execute_reply": "2022-10-15T00:06:08.894220Z"
    },
    "papermill": {
     "duration": 0.018591,
     "end_time": "2022-10-15T00:06:08.897539",
     "exception": false,
     "start_time": "2022-10-15T00:06:08.878948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c8e23a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T00:06:08.909892Z",
     "iopub.status.busy": "2022-10-15T00:06:08.909513Z",
     "iopub.status.idle": "2022-10-15T00:06:08.918184Z",
     "shell.execute_reply": "2022-10-15T00:06:08.917136Z"
    },
    "papermill": {
     "duration": 0.017614,
     "end_time": "2022-10-15T00:06:08.920526",
     "exception": false,
     "start_time": "2022-10-15T00:06:08.902912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e8a942",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T00:06:08.933246Z",
     "iopub.status.busy": "2022-10-15T00:06:08.932856Z",
     "iopub.status.idle": "2022-10-15T00:06:08.941486Z",
     "shell.execute_reply": "2022-10-15T00:06:08.940265Z"
    },
    "papermill": {
     "duration": 0.01749,
     "end_time": "2022-10-15T00:06:08.943690",
     "exception": false,
     "start_time": "2022-10-15T00:06:08.926200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5156d60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T00:06:08.956747Z",
     "iopub.status.busy": "2022-10-15T00:06:08.956372Z",
     "iopub.status.idle": "2022-10-15T00:06:11.185629Z",
     "shell.execute_reply": "2022-10-15T00:06:11.184261Z"
    },
    "papermill": {
     "duration": 2.239172,
     "end_time": "2022-10-15T00:06:11.188468",
     "exception": false,
     "start_time": "2022-10-15T00:06:08.949296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.to_csv('./Sampled_speeches/train.csv', index=False)\n",
    "test.to_csv('./Sampled_speeches/test.csv', index=False)\n",
    "val.to_csv('./Sampled_speeches/val.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 50.757684,
   "end_time": "2022-10-15T00:06:12.017318",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-10-15T00:05:21.259634",
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "48cace39d0b04255ae78003876d64bc184d212be70cd059ed579da6df7df9f1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
